{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4d21305-3d72-4668-80b3-d315eca38b98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.1.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5164e472-ba94-4a9d-86f7-a7ccbb44cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610af2cd-545b-405b-8f82-1950424a8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7be993bb-7138-469c-8655-0caba3842f3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.59.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (20.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/mohithrajachava/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e521f1-416f-4fda-b227-9a6f0cf2cfd6",
   "metadata": {},
   "source": [
    "Part 1 is understanding Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313bc09d-13f9-4d09-8531-d2732f486fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark PROPN Mark NNP compound Xxxx True False\n",
      "Zuckerberg PROPN Zuckerberg NNP nsubj Xxxxx True False\n",
      "born VERB bear VBN csubj xxxx True False\n",
      "May PROPN May NNP npadvmod Xxx True True\n",
      "14 NUM 14 CD nummod dd False False\n",
      ", PUNCT , , punct , False False\n",
      "1984 NUM 1984 CD nummod dddd False False\n",
      "in ADP in IN prep xx True True\n",
      "New PROPN New NNP compound Xxx True False\n",
      "York PROPN York NNP pobj Xxxx True False\n",
      "is AUX be VBZ ROOT xx True True\n",
      "an DET an DT det xx True True\n",
      "American ADJ american JJ amod Xxxxx True False\n",
      "technology NOUN technology NN compound xxxx True False\n",
      "entrepreneur NOUN entrepreneur NN attr xxxx True False\n",
      "and CCONJ and CC cc xxx True True\n",
      "philanthropist NOUN philanthropist NN conj xxxx True False\n",
      "best ADV well RBS advmod xxxx True False\n",
      "known VERB know VBN acl xxxx True False\n",
      "for ADP for IN prep xxx True True\n",
      "co NOUN co NN pobj xx True False\n",
      "- ADJ - JJ pobj - False False\n",
      "founding ADJ founding JJ pobj xxxx True False\n",
      "and CCONJ and CC cc xxx True True\n",
      "leading VERB lead VBG conj xxxx True False\n",
      "Facebook PROPN Facebook NNP dobj Xxxxx True False\n",
      "as ADP as IN prep xx True True\n",
      "its PRON its PRP$ poss xxx True True\n",
      "chairman NOUN chairman NN pobj xxxx True False\n",
      "and CCONJ and CC cc xxx True True\n",
      "CEO PROPN CEO NNP conj XXX True False\n",
      ". PUNCT . . punct . False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Mark Zuckerberg born May 14, 1984 in New York is an American technology entrepreneur and philanthropist best known for co-founding and leading Facebook as its chairman and CEO.')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be652a0-4d8e-4724-b489-736ef9bd17c0",
   "metadata": {},
   "source": [
    "\n",
    "LEMMA Root form of the word being processed\n",
    "POS Part-of-speech of the word\n",
    "TAG They express the part-of-speech (e.g., VERB) and some amount of morphological\n",
    "information (e.g., that the verb is past tense).\n",
    "DEP Syntactic dependency (i.e., the relation between tokens)\n",
    "SHAPE Shape of the word (e.g., the capitalization, punctuation, digits format)\n",
    "ALPHA Is the token an alpha character?\n",
    "Stop Is the word a stop word or part of a stop list?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e9183-e26b-4213-bb34-4e58a035af94",
   "metadata": {},
   "source": [
    "Stemming and lammatization:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa8a3bd4-02d3-43e9-b3f6-f567993a396c",
   "metadata": {},
   "source": [
    "Stemming: Stemming does the job in a crude, heuristic way that chops off the\n",
    "ends of words, assuming that the remaining word is what we are\n",
    "actually looking for, but it often includes the removal of derivational\n",
    "affixes.\n",
    "\n",
    "lammatization: Lemmatization tries to do the job more elegantly with the use of a\n",
    "vocabulary and morphological analysis of words. It tries its best to\n",
    "remove inflectional endings only and return the dictionary form of a\n",
    "word, known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b2022b-41e6-4867-8188-6aacdc12254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Mark\n",
      "Zuckerberg Zuckerberg\n",
      "born bear\n",
      "May May\n",
      "14 14\n",
      ", ,\n",
      "1984 1984\n",
      "in in\n",
      "New New\n",
      "York York\n",
      "is be\n",
      "an an\n",
      "American american\n",
      "technology technology\n",
      "entrepreneur entrepreneur\n",
      "and and\n",
      "philanthropist philanthropist\n",
      "best well\n",
      "known know\n",
      "for for\n",
      "co co\n",
      "- -\n",
      "founding founding\n",
      "and and\n",
      "leading lead\n",
      "Facebook Facebook\n",
      "as as\n",
      "its its\n",
      "chairman chairman\n",
      "and and\n",
      "CEO CEO\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564453c5-2726-4ee6-a988-cc1111da9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7c1c69-c09f-456a-b38f-b11dabe562a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f408441-96ec-4bba-b35c-a8c270a9acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b56f0f95-2946-4ad9-8078-bc2b8e9886e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster\n",
      "faster\n"
     ]
    }
   ],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "print(porter_stemmer.stem('faster'))\n",
    "print(snowball_stemmer.stem('faster'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97cd9349-4653-4daf-92f8-f44c5382a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Zuckerberg PERSON\n",
      "May 14, 1984 DATE\n",
      "New York GPE\n",
      "American NORP\n"
     ]
    }
   ],
   "source": [
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f53127f-6875-4002-b424-e88e504d8037",
   "metadata": {},
   "source": [
    "Understandig entity in a doc gives fair idea of what context is "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3dfdb74-4d6f-4569-b81e-1f7c1efb693d",
   "metadata": {},
   "source": [
    "Stopwords : stop-words are the high frequency words that repeat in a doc which we sometimes need to remove while processing to get a better idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9360f06e-fd3f-4cbc-9c5d-d88121b9056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41d1284-8fbe-4455-b89b-63a818910666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whereafter', 'however', 'whole', 'out', 'someone', 'an', \"'re\", 'your', 'none', '’ll', 'whatever', 'her', 'sometime', 'all', 'own', 'thus', 'is', 'done', 'what', 'least', 'ourselves', 'hers', 'sixty', 'first', 'was', 'twelve', 'never', 'thereby', 'i', 'between', 'perhaps', 'to', 'somewhere', 'unless', 'no', 'can', 'much', 'he', 'part', 'eleven', 'wherever', 'might', 'seemed', 'except', 'any', 'not', 'often', 'n’t', 'otherwise', 'if', 'am', 'upon', 'forty', 'along', 'every', 'this', 'became', 'those', 'by', 'under', 'nothing', 'something', 'front', 'beyond', 'four', 'after', 'the', 'three', 'same', 'once', 'mostly', 'make', 'namely', 'last', 'some', 'again', 'we', 'over', 'whither', 'than', 'should', 'so', 'while', 'up', \"'ve\", 'anything', 'due', 'noone', 'before', 'beside', 'somehow', 'throughout', 'neither', '‘d', 'indeed', 'eight', 'with', 'doing', 'will', 'top', 'give', 'since', 'yet', 'n‘t', 'many', 'mine', 'his', 'next', 'just', 're', 'be', 'ca', 'here', 'onto', 'besides', '‘s', 'empty', 'how', 'me', 'whereby', 'latter', 'name', 'must', 'take', 'moreover', 'around', 'few', '‘m', 'itself', 'its', 'may', 'without', 'does', 'call', 'only', 'six', 'our', 'on', 'a', 'whereupon', 'seeming', 'regarding', '‘ll', 'within', 'which', 'it', 'rather', 'afterwards', 'wherein', 'down', 'still', 'until', \"'d\", 'say', 'been', 'elsewhere', 'everything', 'several', 'though', 'although', 'him', 'could', 'used', 'off', '’ve', 'such', 'at', 'do', 'anyone', 'ten', 'seems', 'my', 'whom', 'less', 'nobody', 'both', 'becoming', 'always', 'whether', 'various', 'myself', 'too', 'anyway', 'had', 'also', 'seem', 'side', 'across', '’d', 'who', 'you', 'below', 'amongst', 'would', 'thence', 'whoever', 'that', 'fifteen', 'through', 'become', '’m', 'already', 'she', 'latterly', 'toward', 'behind', 'thereupon', 'herself', 'above', 'therefore', 'move', 'two', 'ours', 'therein', 'thru', 'thereafter', 'quite', '‘re', 'sometimes', \"n't\", 'whenever', 'about', 'were', 'together', 'via', 'please', 'now', \"'ll\", 'formerly', 'they', 'where', 'fifty', 'ever', 'did', 'when', 'most', 'enough', 'whence', 'more', 'among', 'being', 'show', 'yourselves', 'there', 'in', 'five', 'further', 'their', 'really', 'hereupon', 'else', 'bottom', 'are', 'because', 'nevertheless', '’re', 'meanwhile', \"'s\", 'yourself', 'almost', 'into', 'and', 'towards', '‘ve', 'themselves', 'everywhere', 'hereafter', 'of', 'for', 'hundred', 'yours', 'whereas', 'alone', 'even', 'well', 'full', 'another', 'others', 'third', 'other', 'nine', 'anywhere', 'against', 'former', 'everyone', 'whose', 'herein', 'nor', 'nowhere', '’s', 'why', 'anyhow', 'back', 'but', 'has', 'very', 'us', 'then', 'these', 'from', 'serious', 'hereby', 'see', \"'m\", 'twenty', 'during', 'one', 'becomes', 'either', 'beforehand', 'put', 'made', 'per', 'as', 'keep', 'cannot', 'each', 'using', 'go', 'them', 'or', 'amount', 'get', 'have', 'hence', 'himself'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2326bf48-e6fe-4efd-adc6-b642f392d4a6",
   "metadata": {},
   "source": [
    "DEPENDENCY PARSING : parser is used for detecting sentence boundary and the parsed tree helps understand parent-child relation between words/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341ee97b-537e-425d-973d-08945c03f8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[from, flight, Book]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc  = nlp('Book a flight from hyderabad to LA')\n",
    "\n",
    "hyd, losa = doc[4], doc[6]\n",
    "\n",
    "list(hyd.ancestors) #listing all the ancestors of hyderabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f566449-6de8-485c-bc96-e28db1fe7744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[to, flight, Book]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(losa.ancestors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d5aad-ecbe-4c54-85b8-8eeb90582fdb",
   "metadata": {},
   "source": [
    "Ancestors in dependency parsing are the rightmost token of this token’s syntactic descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c1e6fe-23b9-46af-aac1-4b6226527736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[from, flight, Book]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[4].ancestors) #accessing ancestors using doc index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3b8a0a-e941-4ecb-848a-199ec15d596a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check if a doc obj is ancestor of a diff doc obj\n",
    "\n",
    "doc[2].is_ancestor(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4641ecd3-52de-40b8-8d44-c3c4beff84d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking of table belongs to restaurent\n",
      "Booking of taxi belongs to hotel\n"
     ]
    }
   ],
   "source": [
    "# understanding multiple tasks and targets\n",
    "\n",
    "doc = nlp(\"Book a table at the restaurent and the taxi to the hotel\")\n",
    "\n",
    "tasks = doc[2],doc[8]  #assigning table and taxi as tasks\n",
    "\n",
    "tasks_target = doc[5], doc[11] # assigning restaurent and hotel as targets\n",
    "\n",
    "for task in tasks_target:\n",
    "    for tok in task.ancestors:\n",
    "        if tok in tasks:\n",
    "            print(\"Booking of {} belongs to {}\".format(tok,task))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df544d39-03a6-4d38-9bb5-5054c53de5d1",
   "metadata": {},
   "source": [
    "Children in dependency parsing are immediate syntactic dependents of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f7d1ab-a9d1-4931-9251-8c5129dbc1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[the, and, taxi]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[5].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acd1413a-594e-4c01-98bc-6b0defa57dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a, at]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc[2].children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b6d3ef0-ffa4-4769-b6ac-c2b9600f0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#understanding dependency parser visually\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090915ea-2997-402b-a09e-eaa8690dd9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4e248d47179145c59bf510547290153c-0\" class=\"displacy\" width=\"2150\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Book</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">table</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">restaurent</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">taxi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">hotel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-0\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,179.0 L408.0,167.0 392.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-6\" stroke-width=\"2px\" d=\"M1295,177.0 C1295,89.5 1445.0,89.5 1445.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,179.0 L1287,167.0 1303,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-7\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1450.0,2.0 1450.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,179.0 L1458.0,167.0 1442.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-8\" stroke-width=\"2px\" d=\"M1470,177.0 C1470,89.5 1620.0,89.5 1620.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,179.0 L1628.0,167.0 1612.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-9\" stroke-width=\"2px\" d=\"M1820,177.0 C1820,89.5 1970.0,89.5 1970.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,179.0 L1812,167.0 1828,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e248d47179145c59bf510547290153c-0-10\" stroke-width=\"2px\" d=\"M1645,177.0 C1645,2.0 1975.0,2.0 1975.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e248d47179145c59bf510547290153c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1975.0,179.0 L1983.0,167.0 1967.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Book a table at the restaurent and the taxi to the hotel\")\n",
    "displacy.render(doc, style='dep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd8a0a08-d95e-4d53-a7fc-9cbf307fe634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user is refering Berlin to visit\n",
      "user is refering Lubec to stay\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"What are some places to visit in Berlin and stay in Lubec\")\n",
    "places = doc[7], doc[11]\n",
    "actions = doc[5], doc[9]\n",
    "\n",
    "for place in places:\n",
    "    for tok in place.ancestors:\n",
    "        if tok in actions:\n",
    "            print(\"user is refering {} to {}\".format(place, tok))\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff2f0b-6aeb-4f85-b0d9-8af5cffb9268",
   "metadata": {},
   "source": [
    "Noun-chunks: These are basically base noun phrases, that have a noun as their head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d07371-1075-4b14-a2f8-17f7c24775dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Boston Dynamics, thousands, robot dogs]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understanding noun-chunks in a sentence\n",
    "\n",
    "doc = nlp(\"Boston Dynamics is gearing up to produce thousands of robot dogs \")\n",
    "\n",
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "858b4260-c1a7-4e5b-b062-e8e6e5e23ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLearning DeepLearning nsubj cracks\n",
      "the code code dobj cracks\n",
      "messenger RNA RNA pobj of\n",
      "coding potential potential dobj cracks\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"DeepLearning cracks the code of messenger RNA's and protien coding potential\")\n",
    "\n",
    "for chunk in doc2.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41965534-d4f8-4c0a-ad64-dca226aeb99f",
   "metadata": {},
   "source": [
    "Exploring GloVe to understand similarity between two words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b46452-891a-4bc7-858a-9c32cda7a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How [ 1.6143672  -0.4711746   0.39407504  2.1231742   0.16744262]\n",
      "good [ 1.0237651  -1.3570685   0.04195169  0.84736043 -0.49153998]\n",
      "is [-0.49836892  0.70540786 -0.3299709   0.62666774 -0.52085745]\n",
      "google [-0.48117828 -1.0377525   0.27524015  1.2639378   0.04486725]\n",
      "'s [2.0742245  2.1592314  0.17449465 0.7083967  0.3253508 ]\n",
      "new [ 0.6110381  -1.0594106   0.90315354  1.34445     0.14536023]\n",
      "A.I [ 0.02554996 -1.473116    0.6940452   0.57291913  0.22437394]\n",
      "bot [-0.5032579  -1.3603683  -0.5172367   0.09713605  0.9227977 ]\n",
      "BRAD [-0.85609686 -0.7711649   0.64675206  0.00531679  0.12968323]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"How good is google's new A.I bot BRAD\")\n",
    "for token in doc:\n",
    "    print(token.text, token.vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c382d9c-043e-453e-8bd9-2045ae2aa283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7161105600799103\n",
      "0.596996698990903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-b36e40e921eb>:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(hello_doc.similarity(hi_doc))\n",
      "<ipython-input-33-b36e40e921eb>:8: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(hello_doc.similarity(hella_doc))\n"
     ]
    }
   ],
   "source": [
    "#exploring similar words using their vectors \n",
    "\n",
    "hello_doc = nlp(\"hello\")\n",
    "hi_doc = nlp(\"hi\")\n",
    "hella_doc = nlp(\"hella\")\n",
    "\n",
    "print(hello_doc.similarity(hi_doc))\n",
    "print(hello_doc.similarity(hella_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "773b3d23-4c9a-4a8e-96be-cc84ec818016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49713212617227265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-095716bb5885>:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(got_str1.similarity(got_str2))\n"
     ]
    }
   ],
   "source": [
    "#understanding similarity in strings \n",
    "\n",
    "got_str1 = nlp(\"When Will next season of Game of Thrones be releasing?\")\n",
    "got_str2 = nlp(\"Game of Thrones next season release date?\")\n",
    "\n",
    "print(got_str1.similarity(got_str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764a87d-cc5e-4aec-9526-5ca16f946c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
